---
title: "PODWORDS"
tags:
  - DÃ©monstrateur
  - Podwords
  - "2024"
excerpt : "DÃ©monstrateur - Jouez avec lâ€™embedding des mots ! <br>- DifficultÃ© : dÃ©butant"
header:
   overlay_color: "#1C2A4D"
author_profile: false
sidebar:
    nav: sidebar-divers
classes: wide
---

# Introduction
<p style="text-align:justify;">
Dans une <a href="https://blog.vaniila.ai/Word_embedding/">note de blog prÃ©cÃ©dente</a>, nous prÃ©sentions les fondements thÃ©oriques de lâ€™<i>embedding</i> de mots. 
Ici, nous prÃ©senterons comment un modeste modÃ¨le de ce type peut suffire Ã  construire un outil capable de jouer Ã  une variante du cÃ©lÃ¨bre jeu de sociÃ©tÃ© <a href="https://iello.fr/jeux/codenames/">Code Names</a> : <a href="https://pod-words.vaniila.ai/index.html">Podwords</a>.</p>  
<br><br> 


# Motivation
<p style="text-align:justify;">
  Le but nâ€™est pas un concours de la plus grosse IA. Au contraire, on cherche ici Ã  voir jusqu'oÃ¹ on peut aller dans la complexitÃ© de tÃ¢che adressÃ©e, avec l'outil le plus minimaliste possible. 
  En somme, faire le maximum avec le minimum. Jouer Ã  une sorte de Code Names, sans jeu de donnÃ©es de parties jouÃ©es, sans rÃ©seau de neurones complexe, mais avec un simple jeu dâ€™<i>embedding</i> de mots courants.
</p>
<br><br> 

# ModÃ¨le d'<i>embedding</i>

## DÃ©finition
<p style="text-align:justify;">
Pour les intÃ©ressÃ©s, les fondamentaux mathÃ©matiques sont consultables dans notre <a href="https://blog.vaniila.ai/Word_embedding/">note de blog prÃ©cÃ©dente</a>. 
Ici, le parti-pris est de prÃ©senter trÃ¨s simplement les choses, en se contentant de donner lâ€™intuition.

Prenons lâ€™analogie suivante : Â« Lâ€™<i>embedding</i> est aux <a href="https://fr.wikipedia.org/wiki/Grand_mod%C3%A8le_de_langage">LLM</a>, ce quâ€™est la roue Ã  une charrette Â».   

Ceci est loin de donner une dÃ©finition satisfaisante de lâ€™<i>embedding</i>. Cependant, elle permet de se reprÃ©senter les choses.
Il y a une relation entre lâ€™<i>embedding</i> et les LLM. 
Il y a une relation entre une roue et une charrette. Ces relations sont similaires. 
SchÃ©matiquement, ces relations sont des vecteurs et ces deux vecteurs sont Ã©gaux. 
Mais comment dÃ©crire cette relation ? On peut identifier des composants au vecteur de la relation :  <br>
- Â« est un composant de Â» <br> 
- Â« a Ã©tÃ© inventÃ© avant Â»  <br>
- Â« est plus simple que Â»  <br>
- Â« a moins de capacitÃ© que Â»
</p>
<br>

<center>
<figure class="image">
  <img src="https://raw.githubusercontent.com/catie-aq/blog-vaniila/main/assets/images/Podwords/Image_1.png" width="400">
  <figcaption>
  <i>Concevoir que le sens des mots peut Ãªtre dÃ©crit dans un espace sÃ©mantique, câ€™est concevoir quâ€™il puisse y avoir une reprÃ©sentation vectorielle dâ€™un mot. DÃ©finir un modÃ¨le dâ€™embedding, câ€™est choisir les axes qui structurent lâ€™espace sÃ©mantique.
NB : Le mot dÃ©crivant les relations A et B (qui sont Ã©gales) nâ€™existe peut-Ãªtre pas, mais le vecteur en dÃ©crivant le sens existe.</i>
  </figcaption>
</figure>
</center>
<br>

<p style="text-align:justify;">
Eh bien, choisir un modÃ¨le dâ€™<i>embedding</i>, c'est-Ã -dire un outil qui donne la reprÃ©sentation vectorielle dâ€™un mot, câ€™est choisir un certain nombre de composants structurant lâ€™espace des mots pour rendre compte de relations entre eux. 
Ã‰videment, comme on veut aussi pouvoir se reprÃ©senter des tas dâ€™autres mots, typiquement de lâ€™ordre de 90 000 pour le franÃ§ais, il va falloir plus de dimensions Ã  notre espace. 
Cependant, lâ€™idÃ©e est lÃ , ne pas avoir une dimension par mot (comme câ€™est le cas pour un <a href="https://fr.wikipedia.org/wiki/Encodage_one-hot">encodage one-hot</a>, mais trouver les bonnes composantes pour rÃ©duire le nombre de dimensions, tout en rendant compte de maniÃ¨re satisfaisante de lâ€™ensemble des relations existantes entre les mots.  

La valeur de lâ€™<i>embedding</i> rÃ©side dans les relations linÃ©aires entre vecteurs que sous-tend la structuration de lâ€™espace choisi. 
Passer Ã  cet espace vectoriel structurÃ© permet le calcul de distance, la projection, voire une arithmÃ©tique dâ€™addition, de soustraction, voire de moyennation des vecteurs dâ€™<i>embedding</i>, et donc des mots. 
Ici, on restera simple et on se contentera de calculer la similitude entre deux mots, par le calcul du <a href="https://fr.wikipedia.org/wiki/Similarit%C3%A9_cosinus">cosinus de leurs vecteurs dâ€™<i>embedding</i></a>.
</p>
<br>

### ModÃ¨le dâ€™<i>embedding</i> utilisÃ©

<p style="text-align:justify;">
Il est naturel que diffÃ©rentes structurations de lâ€™espace des mots soient possibles et donc que diffÃ©rents modÃ¨les dâ€™<i>embedding</i> puissent coexister. 
Ces derniers ont des caractÃ©ristiques et <a href="https://arxiv.org/abs/2210.07316">des performances variables suivant la tÃ¢che adressÃ©e</a>. 

Dans la perspective minimaliste de ce dÃ©monstrateur, nous optons pour Word2Vec. 
Notons que ce nâ€™est pas le modÃ¨le qui est utilisÃ© mais le rÃ©sultat de la modÃ©lisation, i.e. une liste de paires : mot et sa reprÃ©sentation vectorielle. 

Les <i>embeddings</i> utilisÃ©s sont fournis par <a href="https://fauconnier.github.io/">Jean-Philippe Fauconnier</a>, sous la rÃ©fÃ©rence <code>frWac_non_lem_no_postag_no_phrase_200_cbow_cut100</code> (sous licence CC-BY 3.0). 
Ils sont obtenus par lâ€™approche cbow (cf. <a href="https://blog.vaniila.ai/Word_embedding/">la note de blog</a> ou <a href="https://arxiv.org/abs/1301.3781">le papier acadÃ©mique</a> pour plus de dÃ©tails),
sur le corpus <a href="http://wacky.sslmit.unibo.it/doku.php?id=corpora">FrWac corpus</a>.  
Construit en 2008, il est bÃ¢ti sur un corpus de 1,6 milliard de mots, Ã  partir du Web en limitant l'exploration au domaine <code>.fr</code>. Les vecteurs sont de dimension 200. 
Il est important de noter que ces dimensions ne sont pas des concepts explicites comme lâ€™exemple prÃ©cÃ©dent, mais des notions  Â« machines Â» basÃ©es sur des frÃ©quences dâ€™apparitions.  
Par ailleurs, pour amÃ©liorer lâ€™expÃ©rience de jeu, certains mots ont Ã©tÃ© Ã©cartÃ©s du corpus. 
Il sâ€™agit de mots trop frÃ©quents, de mots trop mÃ©connus ou encore injurieux (ex: Â« de Â», Â« agÃ©laste Â», â€¦).
<br><br>

<aside><i> ğŸ’¡ Faites des Schtroumpfs !<br>  
On pourrait envisager de permettre aux joueurs dâ€™utiliser <a href="https://huggingface.co/models?search=word%20embedding">diffÃ©rents modÃ¨les dâ€™<i>embedding</i></a> et ainsi explorer lesquels leur semblent les plus adaptÃ©s pour formuler des propositions lors dâ€™une partie de Podwords.   
Est-ce que des modÃ¨les plus sophistiquÃ©s, qui travaillent Ã  lâ€™Ã©chelle dâ€™une phrase pour rendre compte du contexte dâ€™un mot, sont plus efficaces que ce bon vieux Word2Vec ? Pourquoi ne pas essayer des modÃ¨les comme le dernier modÃ¨le <a href="https://platform.openai.com/docs/guides/embeddings/embedding-models">dâ€™<i>embedding</i> dâ€™Open AI utilisÃ© pour ChatGPT</a> ?   
Et ne pourrait-on voir Ã©merger une Ã©bauche de Â« persona Â» en comparant des modÃ¨les entrainÃ©s sur des corpus diffÃ©rents ? Par exemple, un corpus de texte issu de Wikipedia donnerait-il des indices Â« de schtroumpf Ã  lunettes Â» ? En comparaison, que donnerait un modÃ¨le dâ€™<i>embedding</i> bÃ¢ti sur un corpus de tweets, une Â« schtroumpf grognon Â» ?
</i></aside></p>
<br><br>

# GÃ©nÃ©rer des indices

<p style="text-align:justify;">
Câ€™est entendu, lâ€™idÃ©e ici sera de crÃ©er un programme capable de proposer des mots indices dans une partie de Podwords, en partant uniquement dâ€™un set de vecteurs dâ€™<i>embedding</i> pour les mots les plus frÃ©quents de la langue franÃ§aise. 
  Voyons comment faire cela simplement.

On passera sur certaines fonctionnalitÃ©s simples du moteur de jeu, comme dÃ©terminer lorsqu'une partie est gagnÃ©e ou perdue par exemple,  pour se concentrer sur la tÃ¢che qui nous intÃ©resse ici : comment, Ã  partir de lâ€™information sur lâ€™Ã©tat du jeu, formuler une proposition dâ€™indice ?

Une proposition dâ€™indice se compose de deux Ã©lÃ©ments :<br>
- un mot indice - qui ne doit pas Ãªtre de la mÃªme famille quâ€™un des mots encore non dÃ©signÃ© sur la grille<br>
- un nombre de mots ciblÃ©s - qui est une indication au joueur sur le nombre de mots <i>ciblÃ©s</i> quâ€™il devrait pouvoir pointer avec ce mot indice<br>

On peut dÃ©composer le processus de gÃ©nÃ©ration en deux Ã©tapes.
</p>


<center>
<figure class="image">
  <img src="https://raw.githubusercontent.com/catie-aq/blog-vaniila/main/assets/images/Podwords/Image_2.png" width="450">
  <figcaption>
  <i>Interface du dÃ©monstrateur Podwords. Ici le programme donne comme mot indice Foot, et comme nombre de mots ciblÃ©s 2.</i>
  </figcaption>
</figure>
</center>
<br>

<p style="text-align:justify;">
On dispose Ã  ce stade de lâ€™Ã©tat de la grille. On peut alors Ã©carter les mots dÃ©jÃ  pointÃ©s par lâ€™utilisateur, qui ne sont plus Â« actifs Â». 
A noter, pour les autres mots, le programme Â« sait Â» sâ€™ils sont Ã  faire deviner, neutres ou tabous.

En rÃ©sumÃ©, les Ã©tapes sont les suivantes (on va dÃ©tailler cela ci-dessous) :  <br>
1) crÃ©er la liste de tous les groupes de mots cibles possibles   <br>
2) pour chaque groupe  <br>
	2.1) obtenir une liste de <i>n</i> mots indices candidats  <br>
	2.2) affiner le calcul du score des mots indices candidats, pour selectionner le meilleur  <br>
3) pour chaque taille de groupe, dÃ©terminer la meilleure proposition (paire indice:groupe_mots_cibles)  <br>
4) sÃ©lectionner parmis les propositions ayant une score de facilitÃ© suffisant, la proposition du plus grand groupe de mots cibles.<br><br>


<b>Ã‰tape 1</b> : elle consiste Ã  lister lâ€™ensemble des <a href="https://fr.wikipedia.org/wiki/Combinaison_sans_r%C3%A9p%C3%A9tition">combinaisons possibles</a> de groupes de mots Ã  faire deviner (sans rÃ©pÃ©tition, ni ordre). 
On considÃ¨re ainsi tous les groupes possibles de 1 mot parmi les <i>n</i>, de 2 mots, etc. jusquâ€™au seul groupe possible de <i>n</i> mots.
</p>

<center>
<figure class="image">
  <img src="https://raw.githubusercontent.com/catie-aq/blog-vaniila/main/assets/images/Podwords/Image_3.png" width="450">
  <figcaption>
  <i>Ã‰tablissement de la liste de tous les groupes possibles de mots cibles (nombre de groupes de 1 mot C 4:1 = 4 en jaune, nombre de groupes de 2 mots C 4:2 = 6 en rose, â€¦)</i>
  </figcaption>
</figure>
</center>
<br>

<p style="text-align:justify;">
<b>Ã‰tape 2.1</b> :  elle fournit, pour chaque groupe, une liste de <i>n</i> mots indices candidats. 
Ces mots sont ceux qui sont Ã  la fois le plus proche possible des mots cible et le plus loin des mots tabous (oui, Ã  ce stade, on ignore les mots neutres). 
Pour ce faire, le barycentre de lâ€™ensemble des vecteurs dâ€™<i>embedding</i> des mots est calculÃ©, avec une pondÃ©ration positive pour les mots cibles et une pondÃ©ration nÃ©gative pour les mots tabous. 
Les <i>n</i> mots indices candidats les plus proches de ce barycentre sont alors retournÃ©s. 
Cette approximation peut potentiellement dÃ©grader la qualitÃ© des indices gÃ©nÃ©rÃ©s. 
Mais elle vise Ã  restreindre le nombre de mots indices candidats qui seront passÃ©s Ã  lâ€™Ã©tape suivante. 
Sans considÃ©ration pour le coup de calcul, on pourrait ignorer cette Ã©tape et passer lâ€™ensemble des mots du corpus Ã  lâ€™Ã©tape suivante.  <br>

En outre, Ã  cette Ã©tape, on dÃ©termine pour chacun des <i>n</i> mots indices candidats sâ€™il est valide. 
Il est invalide sâ€™il est de la mÃªme famille lexicale quâ€™un des mots de la grille non encore dÃ©couverts. 
Pour cacher la poussiÃ¨re sous le tapis, on prÃ©tendra ici quâ€™il sâ€™agit dâ€™une trivialitÃ©. 
MÃªme si en rÃ©alitÃ©, la solution dÃ©ployÃ©e a des ratÃ©s, elle laisse passer des indices invalides.    <br><br>

<b>Ã‰tape 2.2</b> : elle consiste Ã  affiner le calcul pour chacun des <i>n</i> mots retournÃ©s par la prÃ©cÃ©dente Ã©tape, pour dÃ©terminer le mot indice le plus adaptÃ© pour chaque groupe de mots cibles. 
Ainsi, pour chaque groupe de mots cibles, et pour chacun de ses mots indices candidat, on :  <br>
- mesure la proximitÃ© maximale entre le mot indice et chacun des mots tabous dâ€™une part ainsi que chacun des mots neutres dâ€™autre part. On cherche ici Ã  mesurer Â« le pire cas Â», câ€™est pourquoi on retient la similaritÃ© la plus forte (i.e. la distance la plus faible) pour chacune des deux catÃ©gories. <br> 
- fait la somme pondÃ©rÃ©e des deux proximitÃ©s obtenues, avec un poids pour les mots tabous cinq fois supÃ©rieur Ã  celui des mots neutres. En effet, il est plus gÃªnant dâ€™Ãªtre proche dâ€™un mot tabou, qui entraÃ®ne instantanÃ©ment la fin de partie, que dâ€™un mot neutre qui ne fait que terminer le tour.  <br>
- mesure la proximitÃ© la plus faible entre le mot indice et chacun des mots cibles. LÃ  encore, on recherche le cas le plus dÃ©favorable.<br>  
- calcule le ratio entre deux quantitÃ©s, la proximitÃ© minimale vis-Ã -vis dâ€™un mot cible, sur la proximitÃ© maximale dâ€™un mot non ciblÃ© (cf. la somme prÃ©cÃ©dente).  <br>
- normalise le ratio pour passer dâ€™une valeur dÃ©finie entre [-1, 1], vers un score dÃ©fini sur lâ€™intervalle [0, 1].  <br>

Ce score reprÃ©sente la Â« facilitÃ© Â», plus ce score est Ã©levÃ©, plus le mot indice permet Ã  lâ€™utilisateur de trouver facilement les mots cibles du groupe.
</p>

<center>
<figure class="image">
  <img src="https://raw.githubusercontent.com/catie-aq/blog-vaniila/main/assets/images/Podwords/Image_4.png" width="450">
  <figcaption>
  <i>Pour chaque groupe de mot, les mots indices candidats sont inspectÃ©s pour sÃ©lectionner le meilleur en considÃ©rant le â€œpire scÃ©narioâ€. C'est-Ã -dire celui qui est Ã  la fois (i) la plus petite distance maximale Ã  un mot cible, et (ii) la plus grande distance minimale aux mots neutres et tabous (pondÃ©rÃ©s plus fortement).</i>
  </figcaption>
</figure>
</center>
<br>

<p style="text-align:justify;">
<b>Ã‰tape 3</b> : pour chaque taille de groupe (1 mot, 2 motsâ€¦), on ne garde alors que la proposition ayant le score de facilitÃ© le plus Ã©levÃ©. 
  Soit deux groupes A et B de mÃªme taille n. Si le score de facilitÃ© de A est supÃ©rieur au score de B,  alors pour la taille de groupe <i>n</i>, câ€™est la proposition A (et son mot indice correspondant) qui sera retenue.<br><br>

<b>Ã‰tape 4</b> : Ã  lâ€™issue de lâ€™Ã©tape prÃ©cÃ©dente, on dispose donc dâ€™une liste de groupes de mots cibles, un par taille, et pour chacun le meilleur mot indice, avec son score de facilitÃ©. 
Toujours dans une approche minimaliste, deux conditions complÃ©mentaires sont utilisÃ©es. 
La proposition retenue sera celle ayant le plus grand score de facilitÃ©, sauf si des propositions ont un score supÃ©rieur Ã  un certain seuil, auquel cas câ€™est la proposition correspondant au plus grand groupe de mots cibles qui sera sÃ©lectionnÃ©e. 
En effet, parvenir Ã  faire deviner en un tour 3 mots cibles a plus de valeur que de faire deviner 1 mot cible.  
<br>

Avec cette mÃ©canique simple, le programme parvient globalement Ã  formuler des propositions cohÃ©rentes pour un utilisateur humain. Les performances nâ€™ont pas Ã©tÃ© mesurÃ©es en conditions rigoureuses. Nos expÃ©rimentations informelles semblent toutefois indiquer que la machine permet un taux de victoire de lâ€™utilisateur analogue Ã  celui obtenu lorsque câ€™est un humain relativement dÃ©butant Ã  ce jeu qui gÃ©nÃ¨re des indices.
<br><br>

<aside><i> ğŸ’¡ Ajoutez une boite de vitesse !<br> 
On pourrait envisager dâ€™ajouter un peu de complexitÃ© dans le programme, en Ã©change dâ€™un gain notable de qualitÃ© des propositions. Pour ce faire, pourquoi ne pas affiner le mÃ©canisme de sÃ©lection finale des propositions ? On pourrait ainsi sophistiquer la fonction de scoring en ajoutant quelques paramÃ¨tres.  
PremiÃ¨rement, il conviendrait de rendre comparables les propositions correspondant Ã  des tailles de groupe diffÃ©rentes. Il sâ€™agit ici de considÃ©rer le gain (espÃ©rÃ©) associÃ© Ã  la proposition candidate pour chaque taille de groupe. La composition du score de facilitÃ© et du gain permet de dÃ©terminer un score global qui soit comparable entre toutes les propositions candidates, quelle que soit la taille du groupe de mots cibles. On sÃ©lectionnerait alors simplement la proposition ayant le score global le plus Ã©levÃ©.  
Une seconde amÃ©lioration serait de prendre en compte lâ€™avancement de la partie, et plus uniquement lâ€™Ã©tat de la grille. En effet, sâ€™il ne reste plus quâ€™un tour mais trois mots cibles, il faudra idÃ©alement accepter de prendre un peu plus de risques pour pouvoir gagner. De mÃªme, le gain devrait prendre en compte le nombre de mots restant, pour devenir un gain relatif. Faire deviner 2 mots lorsquâ€™il en reste 5 nâ€™a pas la mÃªme valeur relative que lorsqu'il nâ€™en reste plus que 2. 
</i></aside></p>
<br><br>


# Comprendre les propositions de l'algorithme

<p style="text-align:justify;">
Que ce soit avec un humain ou une machine, lorsqu'on joue Ã  Code Names, une question revient rÃ©guliÃ¨rement Â« mais pourquoi ce choix dâ€™indice ? Â». 
Dans le cas prÃ©sent, le mÃ©canisme de gÃ©nÃ©ration des indices en lui-mÃªme est simple. Ce qui est difficile est lâ€™apprÃ©hension de la reprÃ©sentation des mots que se fait la machine.
Ici les notions dâ€™explicabilitÃ© et dâ€™interprÃ©tabilitÃ© se chevauchent. 
Pour rendre plus comprÃ©hensible une proposition, il faudrait donc pouvoir reprÃ©senter lâ€™espace des vecteurs dâ€™<i>embedding</i> quâ€™utilise la machine, soit un espace Ã  200 dimensions. 
Quand on voit  <a href="https://fr.wikipedia.org/wiki/Hypercube">la tÃªte dâ€™un carrÃ© lorsqu'il passe en dimension 4</a>, on pressent que cela ne peut pas se faire directement. 
Du moins si lâ€™on vise Ã  rendre les choses plus explicites pour un esprit humain. 
Il faut trouver un moyen de synthÃ©tiser lâ€™information pour quâ€™elle soit accessible Ã  un esprit qui se contente de caboter en 3 voire 4 dimensions. Deux fonctionnalitÃ©s ont Ã©tÃ© dÃ©veloppÃ©es pour ce faire.  

Notons que ces outils sont cohÃ©rents avec la dÃ©marche dâ€™exploration de lâ€™<i>embedding</i>. 
Mais ces fonctionnalitÃ©s sont orthogonales Ã  lâ€™aspect ludique de Podwords. 
En cherchant Â« Ã  comprendre la machine Â» quand elle joue Ã  nous faire deviner, on accÃ¨de Ã  des informations qui doivent Ãªtre ignorÃ©es pour quâ€™il y ait jeu, comme la catÃ©gorie cachÃ©e de chaque mot sur la grille.
</p>
<br><br> 


## Matrice de distance

<p style="text-align:justify;">
La vue Â« Matrice Â» affiche la distance pour chacune des paires de mots que l'on peut constituer (avec les mots non rÃ©vÃ©lÃ©s de la grille plus l'indice). 
Chaque ligne et chaque colonne reprÃ©sentent un mot. 
L'intersection des deux lignes donne la distance entre les deux mots. La coloration bleue Ã  noire indique une distance faible, tandis que l'orange indique une distance Ã©levÃ©e. 
En somme, cette reprÃ©sentation compresse lâ€™information issue de lâ€™espace dâ€™<i>embedding</i> pour ne garder quâ€™une valeur, un score (tirÃ© du calcul de similaritÃ© entre les vecteurs par le calcul du cosinus), sans dimension, facilement assimilable par lâ€™esprit humain.
</p>

<center>
<figure class="image">
  <img src="https://raw.githubusercontent.com/catie-aq/blog-vaniila/main/assets/images/Podwords/Image_5.png" width="450">
  <figcaption>
  <i>La matrice des distances permet de figurer pour chaque mot (en ligne ou en colonne) la distance perÃ§ue par la machine pour chaque autre mot de la grille (ainsi quâ€™avec lâ€™indice en cours en violet). Ici la ligne Â« Menu Â» donne les distances de ce mot avec tous les autres, idem pour la colonne Â« Carte Â». Les carrÃ©s noirs indiquent que dans lâ€™espace dâ€™embedding utilisÃ©, Â« Foot Â» est trÃ¨s proche de Â« Club Â», et Â« Table Â» de Â« Ronde Â» (si ces derniers Ã©taient des mots cibles Â« Graal Â» pourrait Ãªtre un bon indice, mais pas si lâ€™un des deux mots est neutre ou pire, tabou).</i>
  </figcaption>
</figure>
</center>
<br>

<p style="text-align:justify;">
De plus, l'ordre des mots sur chaque axe est arrangÃ© de maniÃ¨re Ã  mieux faire ressortir les zones de paires ayant une forte ou une faible distance. 
Pour ce faire, on dÃ©termine lâ€™ordre des mots par un <a href="https://academic.oup.com/bioinformatics/article/17/suppl_1/S22/261423">algorithme dâ€™optimisation de l'ordonnancement linÃ©aire des feuilles des arbres gÃ©nÃ©rÃ©s par le regroupement hiÃ©rarchique</a> (en somme, on cherche Ã  optimiser la maniÃ¨re de reprÃ©senter un dendrogramme).
</p>

<br>

<center>
<figure class="image">
  <img src="https://raw.githubusercontent.com/catie-aq/blog-vaniila/main/assets/images/Podwords/Image_6.png" width="450">
  <figcaption>
  <i>Les distances entre les mots servent de support Ã  la construction dâ€™un dendrogramme. Les nÅ“uds peuvent Ãªtre permutÃ©s pour amÃ©liorer lâ€™ordre dâ€™affichage, de maniÃ¨re Ã  mieux faire ressortir des zones thÃ©matiques dans lâ€™axe. Ici en rouge, lâ€™exemple dâ€™un nÅ“ud permutÃ©, modifiant lâ€™ordre dâ€™affichage des feuilles (1, 2, 3, 4, 5 â‡’ 1, 2, 4, 5, 3). Source <a href="https://academic.oup.com/bioinformatics/article/17/suppl_1/S22/261423">Bar-Joseph et al</a>.</i>    
  </figcaption>
</figure>
</center>
<br><br> 


## Graphe du rÃ©seau de mots

<p style="text-align:justify;">
LÃ  encore, lâ€™idÃ©e centrale est de proposer une reprÃ©sentation simplifiÃ©e des mots de la grille dans lâ€™espace dâ€™<i>embedding</i>. 
La vue Â« RÃ©seau Â» affiche l'indice et l'ensemble des mots non rÃ©vÃ©lÃ©s de la grille par une reprÃ©sentation en 2D des relations entre eux. 
A noter, il ne sâ€™agit pas Ã  proprement parler dâ€™une projection de lâ€™espace 200D de l'<i>embedding</i> vers un espace 2D. 
Ici un plus grand degrÃ© de libertÃ© est pris pour rÃ©aliser le dessin. Lâ€™assignation des positions des nÅ“uds et arrÃªtes sont est rapport avec la position dans lâ€™espace dâ€™<i>embedding</i>, comme pour la matrice. 
Seule lâ€™information de Â« similitude Â» entre paires de mots est exploitÃ©e. 
Un seuil de distance est choisi, de maniÃ¨re Ã  garantir la connexitÃ© du graphe (c'est-Ã -dire qu'il n'y ait pas de groupes de mots dÃ©tachÃ©s du reste). 
Toutes les paires de mots plus proches entre elles que ce seuil, sont reliÃ©es par des arÃªtes. 
Cette reprÃ©sentation est rÃ©alisÃ©e avec <a href="https://www.sigmajs.org/">Sigma JS</a> et plus prÃ©cisÃ©ment lâ€™algorithme <a href="https://hal.sorbonne-universite.fr/hal-01361779v1/document">ForceAtlas2</a>. 
Lorsque deux mots sont considÃ©rÃ©s comme proches (seuillage), ils sont reliÃ©s par un trait (mais ne sont pas forcÃ©ment affichÃ©s Ã  cÃ´tÃ© l'un de l'autre). 
Ainsi, certains mots peuvent n'Ãªtre reliÃ©s qu'Ã  peu d'autres mots, tandis que certains autres mots sont liÃ©s Ã  beaucoup d'autres mots. La valeur numÃ©rique affichÃ©e est la distance entre les mots.  
Afin de permettre Ã  lâ€™utilisateur dâ€™explorer cette reprÃ©sentation de lâ€™espace, la vue est interactive : on peut zoomer, se dÃ©placer sur les cÃ´tÃ©s et mÃªme cliquer sur un mot pour ne voir que lui ainsi que ses voisins directs. 
Lâ€™utilisateur peut par ailleurs complÃ©ter lâ€™affichage par lâ€™ajout dâ€™informations sur la catÃ©gorie des mots du graphe.
</p>

<br>

<center>
<figure class="image">
  <img src="https://raw.githubusercontent.com/catie-aq/blog-vaniila/main/assets/images/Podwords/Image_7.png" width="450">
  <figcaption>
  <i>La projection en 2D de lâ€™espace dâ€™embedding pour les mots de la grille et le mot indice gÃ©nÃ©rÃ©. Le graphe reprÃ©sente les distances entre les mots (nÅ“uds) par un trait (arÃªte) lorsque les mots sont suffisamment proches. On peut ainsi voir se dessiner le graphe des relations entre les mots du point de vue de la similaritÃ©.</i>    
  </figcaption>
</figure>
</center>
<br><br> 

<p style="text-align:justify;">
<aside><i>ğŸ’¡ Expliquez nous Ã§a !<br> 
On pourrait envisager dâ€™ajouter dâ€™autres outils pour approfondir la comprÃ©hension des propositions.  
On pourrait ainsi implÃ©menter des mÃ©thodes dâ€™explicabilitÃ© locale comme les approches <a href="https://arxiv.org/abs/1602.04938">LIME</a> et <a href="https://arxiv.org/abs/1705.07874">SHAP</a>. Lâ€™idÃ©e est de mesurer lâ€™importance de chaque mot de la grille (considÃ©rÃ© comme des <i>features</i> de lâ€™entrÃ©e) sur le mot indice gÃ©nÃ©rÃ© (sortie) en comparant les indices gÃ©nÃ©rÃ©s pour diffÃ©rentes variantes de lâ€™Ã©tat de la grille. Autrement dit, permettre Ã  lâ€™utilisateur de Â« voir Â» quels sont les mots de la grille qui Â« contribuent Â» le plus Ã  gÃ©nÃ©rer ce mot indice. Ou de voir quel aurait Ã©tÃ© le mot indice si tel(s) mot(s) de la grille Ã©tai(en)t absent(s) (voire mÃªme en ajoutant des mots).   
Une alternative plus expÃ©rimentale encore pourrait Ãªtre de demander Ã  un LLM (type chatGPT) de justifier la proposition dâ€™indice. NB : ceci est distinct de demander Ã  un LLM de jouer, mÃªme sâ€™il serait intÃ©ressant en soit de comparer les indices gÃ©nÃ©rÃ©s par le prÃ©sent programme minimaliste et un LLM.
</i></aside></p>
<br><br>

# Conclusion

<p style="text-align:justify;">
Et voila, nous obtenons ainsi <a href="https://pod-words.vaniila.ai/index.html">Podwords</a>. 

Ce dÃ©monstrateur rÃ©ussit Ã  montrer quâ€™avec un mÃ©canisme relativement simple, on peut aller assez loin dans une apparence Â« dâ€™intelligence Â». Ici un simple jeu de vecteurs dâ€™<i>embedding</i> pour des mots courants parvient Ã  adresser une tÃ¢che considÃ©rÃ©e comme difficile par les humains, fournir des indices Ã  Code Names.  
De plus, ses fonctionnalitÃ©s annexes dâ€™explicabilitÃ© permettent Ã  lâ€™utilisateur dâ€™explorer, Ã  travers une projection 2D, comment les mots de la grille sont positionnÃ©s dans lâ€™espace dâ€™<i>embedding</i>. C'est-Ã -dire une reprÃ©sentation de l'univers des mots et des relations qu'ils ont entre eux. Ceci dÃ©taille le mÃ©canisme sous-jacent de crÃ©ation des indices.  
Et la derniÃ¨re gageure est que tout ceci est obtenu au travers d'un objet ludique. Nous espÃ©rons que vous aurez autant de plaisir Ã  jouer Ã  Podwords que nous en avons eu Ã  le dÃ©velopper.  


Alors pourquoi sâ€™arrÃªter en si bon chemin ? Comme indiquÃ© dans les encarts prÃ©cÃ©dents, diffÃ©rentes amÃ©liorations pourraient prolonger ces travaux. Nâ€™hÃ©sitez pas Ã  voter pour nous indiquer quelle suite vous voudriez voir donnÃ©e :<br>
- ğŸ’¡ Faites des Schtroumpfs ! â‡’ Permettre de jouer avec diffÃ©rents modÃ¨les dâ€™<i>embedding</i> et voir comment ils sont plus ou moins adaptÃ©s Ã  la tÃ¢che. Par lÃ  mÃªme, explorer ce qui pourrait Ã©merger de lâ€™utilisation de modÃ¨les dâ€™<i>embedding</i> moins gÃ©nÃ©riques. Peut-on rÃ©ussir Ã  faire emerger des profils ?<br>
- ğŸ’¡ Ajoutez une boite de vitesse ! â‡’ Affiner la mÃ©thode de sÃ©lection de la proposition dâ€™indice retenue, notamment pour permettre de combiner le score de facilitÃ© et celui de gain relatif, en tenant compte de lâ€™avancement de la partie. Est-ce quâ€™ajouter cette petite complexitÃ© augmente sensiblement les performances ?<br>  
- ğŸ’¡ Expliquez nous Ã§a ! â‡’ Enrichir lâ€™explicitation des Ã©lÃ©ments ayant conduit Ã  la formulation dâ€™un indice. Peut-on rendre plus explicite lâ€™importance de chaque mot de la grille sur lâ€™indice gÃ©nÃ©rÃ©, y compris celle des mots tabou et neutres ?<br>

Et pourquoi pas, passer un jour Ã  une variante plus coriace, impliquant la multimodalitÃ© : <a href="https://czechgames.com/en/codenames-pictures/">Code Names Image</a> !
</p>
